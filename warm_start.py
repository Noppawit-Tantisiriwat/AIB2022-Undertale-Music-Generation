### use teacher forcing model to warm-start the window sliding model


### use teacher forcing model to warm-start the window sliding model


import tensorflow as tf
import torch 
from music21 import note, chord, instrument, stream
from torch_models import *
import pickle

#device = "cuda" if torch.cuda.is_available() else "cpu"
device = "cpu"

MODEL_META  = {
    "Tutorial" : {
        "is_teacher_forcing" : False,
        "framework" : "tensorflow",
        "tokenizer" : "./weights/int_to_note.pkl",
        "model" : "./weights/tutorial.hdf5"
    },
    "SingleLSTM" : {
        "is_teacher_forcing" : False,
        "framework" : "torch",
        "tokenizer" : "./weights/int_to_note.pkl",
        "model" : TobyFox(hidden_size=256,possible_notes=1140,embedding_dim=50),
        "state_dict" : "./weights/tobyfox_s_model_50_epochs.pt"
    },
    "BiLSTM" : {
        "is_teacher_forcing" : False,
        "framework" : "torch",
        "tokenizer" : "./weights/int_to_note.pkl",
        "model" : MusicEmbeddingLSTM(embedding_size=50, hidden_size=512, post_embedding=128, vocab_size=1140, bidirectional=True),
        "state_dict" : "./weights/embedded_model_fulldata_50_epochs.pt"
    }, 
    "TeacherForcing" : {
        "is_teacher_forcing" : True,
        "framework" : "torch",
        "tokenizer" : "./weights/teacher_forcing_int_to_note.pkl",
        "model" : TeacherForcingMusicLSTM(Tx=100, embedding_size=50, n_hidden=256, vocab_size=1141, test_size=1),
        "state_dict" : "./weights/teacher_forcing_SimpleLSTM_256_emb50_padding_emb_undertale_200_epochs.pt"
    }
}


def create_midi(prediction_output):
        
    offset = 0
    output_notes = []

            # create note and chord objects based on the values generated by the model
    for pattern in prediction_output:
                # pattern is a chord
        if ('.' in pattern) or pattern.isdigit():
            notes_in_chord = pattern.split('.')
            notes = []
            for current_note in notes_in_chord:
                new_note = note.Note(int(current_note))
                new_note.storedInstrument = instrument.Piano()
                notes.append(new_note)
            new_chord = chord.Chord(notes)
            new_chord.offset = offset
            output_notes.append(new_chord)
                # pattern is a note
        else:
            new_note = note.Note(pattern)
            new_note.offset = offset
            new_note.storedInstrument = instrument.Piano()
            output_notes.append(new_note)

                # increase offset each iteration so that notes do not stack
        offset += 0.25

    return output_notes


def pytorch_generate(model, int_to_note, pattern=None):
    int_to_note = int_to_note
    pattern = pattern.view(100, 1) #if pattern else torch.tensor(np.reshape(random.choices(list(range(len(int_to_note))), k=100), (100, 1)))
    window_size = 100
    prediction_output = []

    # doing auto regressive generation
    for note_indx in range(200):
        prediction_input = pattern.view(1, len(pattern), 1).to(device)[:, note_indx:note_indx+window_size, :]

        prediction, _ = model(prediction_input)
        # get prediction
        index = torch.argmax(prediction, dim=-1)
        
        # get note from prediction
        result = int_to_note[index.item()]
        # add to output
        prediction_output.append(result)
        # add predicted note to the input sequence
        pattern = torch.cat((pattern.cpu(), torch.unsqueeze(index.cpu(), dim=0)), dim=0)
    
    return create_midi(prediction_output), prediction_output


def tensorflow_generate(model, int_to_note, pattern=None):
    

    int_to_note = int_to_note
    pattern = tf.constant(pattern.view(100, 1)) #if tf.constant(pattern.numpy()) else np.reshape(random.choices(list(range(len(int_to_note))), k=100), (100, 1))
    window_size = 100
    prediction_output = []

        # doing auto regressive generation
    for note_indx in range(500):
        prediction_input = tf.reshape(pattern, (1, len(pattern), 1))[:, note_indx:note_indx+window_size, :]

        prediction = model(prediction_input)
        # get prediction
        index = tf.argmax(prediction, axis=-1)
        
        # get note from prediction
        result = int_to_note[index.numpy()[0]]
        # add to output
        prediction_output.append(result)
        # add predicted note to the input sequence
        pattern = tf.concat((pattern, tf.expand_dims(index, axis=0)), axis=0)

    return create_midi(prediction_output), prediction_output


def main(model_name, pattern=None):
    model_config = MODEL_META[model_name]

    if model_config["framework"] == "torch":

        if model_config["is_teacher_forcing"]:
            with open(model_config["tokenizer"], "rb") as f:
                int_to_note = pickle.load(f)

            model = model_config["model"]
            model.load_state_dict(torch.load(model_config["state_dict"],map_location='cpu'))
            model = model.to(device)
            model.eval()

            music_array = torch.transpose(torch.cat(model(torch.randn((1)).to(device)), dim=0), 1, 0)

            
            prediction_output = torch.argmax(music_array, dim=-1)
                
            #prediction_output = np.vectorize(lambda x: int_to_note[x])(prediction_output.cpu())
            
            prediction_output = prediction_output[0]
            

            return prediction_output

            #midi_stream = stream.Stream(music)

            #midi_stream.write("midi", fp=model_name + ".mid")

        else:
            with open(model_config["tokenizer"], "rb") as f:
                int_to_note = pickle.load(f)
            
            model = model_config["model"]
            model.load_state_dict(torch.load(model_config["state_dict"],map_location='cpu'))

            model = model.to(device)

            music, prediction_output = pytorch_generate(model, int_to_note, pattern)

            midi_stream = stream.Stream(music)

            midi_stream.write("midi", fp= "./output/warm_start_"+ model_name + ".mid")

    else:
        model = tf.keras.models.load_model(model_config["model"])
        with open(model_config["tokenizer"], "rb") as f:
            int_to_note = pickle.load(f)

        music, _ = tensorflow_generate(model, int_to_note, pattern)
        #print(music)
        midi_stream = stream.Stream(music)
        midi_stream.write("midi", fp="./output/swarm_start_" + model_name + ".mid")


if __name__ == "__main__":

    prediction_output = main("TeacherForcing")
    main("BiLSTM", prediction_output)

    


    
